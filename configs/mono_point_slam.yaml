verbose: True
dataset: ''
setting: ''          # name of the output folder
stride: 1            # use every X image from the dataset 
max_frames: -1       # use the first X images from the dataset, -1 means using all
only_tracking: False # only do tracking without mapping if enabled
setup_seed: 43
wandb: False         # whether to log through wandb
wandb_folder: /cluster/work/cvl/esandstroem/src/mono_point_slam/output
device: "cuda:0"
silence: False        # if true, no print or log

mapping:
  pretrained: ./pretrained/middle_fine.pt
  geo_iter_ratio: 0.3      # ratio of optimization iters which not involve color loss
  geo_iter_first: 400      # number of geo iters of first mapping frame
  every_keyframe: 1        # do mapping every X keyframes 
  every_frame: 5           # evaluate rendering only every X frames
  frustum_edge: -4         # enlarges image plane a little in frustum feature selection
  fix_geo_decoder: True    # whether to fix the weights of the geometric decoder
  fix_color_decoder: False # used when doing color refinement so that only the features are updated
  mapping_window_size: 5   # X - 2 keyframes used for mapping. 2X used for color refinement step (if used)

  frustum_feature_selection: True      # required for updating a local set of features from the neural point cloud
  keyframe_selection_method: "overlap" # overlap or global. Overlap is described in the paper. Global is just random keyframe selection
  keyframe_setting_method: "period"    # period or motion
  pixels: 1000        # number of sampled rays per frame. M in Point-SLAM paper.
  pixels_adding: 6000 # number of pixels choosing for adding points. X in Point-SLAM paper.
  pixels_based_on_color_grad: 0 # Y in Point-SLAM paper.
  iters_first: 1500  # how many iterations of optimizer for first frame
  iters: 400         # how many iterations of optimizer per mapping stage
  save_rendered_image: True # if True, saves the rgb image also in a separate folder compared to the standard visualization
  min_iter_ratio: 0.95 # mapping iteration lower bound parameter. See Point-SLAM supplementary material

  pix_warping: True       # whether to use pixel warping loss 
  w_pix_warp_loss: 1000.0 # weight for pixel-warping loss term
  w_geo_loss: 1.0         # weight for geo loss term
  w_color_loss: 0.1       # weight of color loss term

  render_depth: "proxy"      # "proxy" or "mono", "proxy" is the proxy depth map mentioned by the paper, "mono" uses monocular depth prior directly instead.
  use_mono_to_complete: True # whether to use mono depth prior to complete the proxy depth map
  save_depth: False          # whether to save the projection-depth and the droid-depth, for debugging only.

  init:
    geometry:
      decoders_lr: 0.001
      geometry_lr: 0.03
      color_lr: 0.0
    color:
      decoders_lr: 0.005
      geometry_lr: 0.005
      color_lr: 0.005
  stage:
    geometry:
      decoders_lr: 0.001
      geometry_lr: 0.03
      color_lr: 0.0
    color:
      decoders_lr: 0.005
      geometry_lr: 0.005
      color_lr: 0.005

tracking:
  pretrained: ./pretrained/droid.pth
  buffer: 512     # maximum number of keyframes that can be stored
  beta: 0.75      # beta * Distance(R|t) + (1-beta) * Distance(I|t), refer to droid_kernels.cu:frame_distance_kernel
  warmup: 8       # use the first X keyframes for bootstrapping the tracker
  max_age: 50     # remove edges in the graph if they have been updated more than X times
  mono_thres: 0.1 # in DSPO, remove the edges if the average disp error of the aligned mono disp is larger than X*average_disp
                  # it can be set to False for keeping all edges.

  motion_filter:
    thresh: 4.0     # add new frame as potential keyframe if avg flow >= X pixels
  multiview_filter:
    thresh: 0.01    # eta in eq(6) of the paper
    visible_num: 2  # points need to be viewed by at least X cameras
  frontend:
    enable_loop: True      # whether to enable loop closure
    enable_online_ba: True # whether to enable online bundle adjustment
    keyframe_thresh: 4.0   # remove keyframe if it is too close to the last keyframe, i.e. avg flow < X pixels
    thresh: 16.0           # only consider edge with avg flow < X pixels
    window: 25             # local ba window size
    radius: 1              # build edges within local window [i-radius, i]
    nms: 1                 # r_local in GO-SLAM paper
    max_factors: 75        # maximum number of edges in local ba
  backend:
    final_ba: True # whether to enable final global bundle adjustment in the end
    ba_freq: 20    # do online bundle adjustment every X keyframes
    thresh: 25.0   # only consider edge with avg flow < X pixels
    radius: 1      # build edges within local window [i-radius, i]
    nms: 5         # r_global in GO-SLAM paper
    # used for loop detection
    loop_window: 25    # N_local in GO-SLAM paper
    loop_thresh: 25.0  # only consider edge with avg flow < X pixels
    loop_radius: 1     # build edges within local window [i-radius, i]
    loop_nms: 12       # r_loop in GO-SLAM paper
    BA_type: "DSPO"    # "DSPO" or "DBA" 
    normalize: True    # whether to normalize disps after each BA iter

cam:
  ### target/output camera settings, camera_size -> resize -> crop -> target_size
  H_edge: 0 
  W_edge: 0 
  H_out: 480
  W_out: 640 

rendering:
  N_surface: 10 # number of samples close to the surface for rendering
  near_end: 0.3 # sample from near end for zero-valued depth pixels
  near_end_surface: 0.95 # rendering interval: 1 - rho in Point-SLAM paper
  far_end_surface: 1.05  # rendering interval: 1 + rho in Point=SLAM paper
  sigmoid_coef: 0.1
  sample_near_pcl: True # sample near the pcl when the pixel depth is zero

data:
  input_folder: ''
  output: ''

meshing:
  gt_mesh_path: ''
  
pointcloud:
  nn_num: 8     # how many nn to choose at most within search radius
  min_nn_num: 2 # if nn_num less than this, will skip this sample location
  N_add: 3      # how many point to add at one location (front and behind gt_depth)
  nn_weighting: "distance" # 'distance'|'expo" whether to use e(-x) or inverse square distance for weighting
  radius_add: 0.04     # radius_add & radius_min are used when dynamic radius is not enabled
  radius_min: 0.02     # used when use_dynamic_radius is False
  radius_query: 0.08   # used when use_dynamic_radius is False
  radius_add_max: 0.08 # r_max, r_min of add and query are used by dynamic radius based on color grad range [0, color_grad_threshold]
  radius_add_min: 0.02
  radius_query_ratio: 2  # when use_dynamic_radius is True, multiply radius add by this factor to get query radius
  color_grad_threshold: 0.15 # threshold for color gradient. This value maps to the smallest search radius
  near_end_surface: 0.95 # adding points interval: 1 - rho in paper
  far_end_surface: 1.05  # adding points interval: 1 + rho in paper
  nlist: 400 # FAISS parameter
  nprobe: 4  # FAISS parameter
  fix_interval_when_add_along_ray: False # when True, adds points equally spread centered at depth (-4 cm to +4 cm) and not dependent on depth
  use_dynamic_radius: True
  bind_npc_with_pose: True # whether to deform the point cloud once previous camera poses and depth maps update

model:
  c_dim: 32 # feature dimension of color and geometric neural points
  exposure_dim: 8 # latent dimension of the exposure compensation features
  pos_embedding_method: fourier # only 'fourier' is used
  encode_rel_pos_in_col: True # encode relative position before color feature interpolation F_THETA
  use_view_direction: True # use viewing direction in color decoder
  encode_viewd: True # encodes view direction in color decoder with fourier embedding when True

mono_prior:
  depth: omnidata      # mono depth model, only omnidata supported for now
  depth_pretrained: ./pretrained/omnidata_dpt_depth_v2.ckpt
  predict_online: True # whether to predict the mono depth prior online, if Fasle, need to pre-run mono prior first and store the mono depth map.
